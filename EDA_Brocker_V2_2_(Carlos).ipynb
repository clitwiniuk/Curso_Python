{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPb3+Z7eiBHaGFr5Pi9DCmw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/clitwiniuk/Curso_Python/blob/master/EDA_Brocker_V2_2_(Carlos).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F9-LIcahItA3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd  # Para la manipulación y análisis de datos\n",
        "import numpy as np  # Para operaciones numéricas\n",
        "import matplotlib.pyplot as plt  # Para la visualización de datos\n",
        "import seaborn as sns  # Para la visualización de datos estadísticos\n",
        "from google.colab import drive  # Para conectarse a Google Drive\n",
        "import os  # Para interactuar con el sistema operativo\n",
        "import re  # Para el procesamiento del texto"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "\n",
        "# Montamos Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Definimos la ruta al archivo de la base de datos\n",
        "file_path = '/content/drive/MyDrive/Proyecto_SmallCaps/BBDD/portapapeles_all_data.db'\n",
        "\n",
        "\n",
        "  # Conectamos a la base de datos\n",
        "conn = sqlite3.connect(file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sE-3oHsCJZz-",
        "outputId": "26683f4a-e29b-4093-9e18-6022e944b480"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(file_path)"
      ],
      "metadata": {
        "id": "lvN4rnuCK3u9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e737835-45c5-424d-e41c-d50b8cfe587d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Proyecto_SmallCaps/BBDD/portapapeles_all_data.db\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Leer la tabla completa\n",
        "data = pd.read_sql(\"SELECT * FROM clipboard_data\", conn)\n",
        "\n",
        "# Mostrar las primeras filas\n",
        "print(\"Estructura original de los datos:\")\n",
        "print(data.head())"
      ],
      "metadata": {
        "id": "oBXfBtIX6z_y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2b9b180-f415-4645-fe94-af1b506e7de0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estructura original de los datos:\n",
            "   id                                            content            timestamp\n",
            "0   1  \"Ticker\"\\t\"Sector\"\\t\"Nombre\"\\t\"Var\"\\t\"%Var\"\\t\"...  2024-12-11 21:33:54\n",
            "1   2  \"Ticker\"\\t\"Sector\"\\t\"Nombre\"\\t\"Var\"\\t\"%Var\"\\t\"...  2024-12-11 21:34:12\n",
            "2   3  \"Ticker\"\\t\"Sector\"\\t\"Nombre\"\\t\"Var\"\\t\"%Var\"\\t\"...  2024-12-11 21:34:31\n",
            "3   4  \"Ticker\"\\t\"Sector\"\\t\"Nombre\"\\t\"Var\"\\t\"%Var\"\\t\"...  2024-12-11 21:34:49\n",
            "4   5  \"Ticker\"\\t\"Sector\"\\t\"Nombre\"\\t\"Var\"\\t\"%Var\"\\t\"...  2024-12-11 21:35:08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Columnas finales requeridas\n",
        "columnas_finales = [\"Ticker\", \"Sector\", \"Nombre\", \"Var\", \"%Var\", \"Ratio vol\", \"Último\",\n",
        "                    \"Volumen\", \"Capital\", \"Spread\", \"Inserción\", \"Anterior\", \"Vol V\",\n",
        "                    \"Vol C\", \"Mínimo\", \"Máximo\", \"Compra\", \"Apertura\", \"Venta\", \"Timestamp\"]\n",
        "\n",
        "# Función para procesar 'content' y organizarlo correctamente\n",
        "def procesar_content(row):\n",
        "    \"\"\"\n",
        "    Procesa una fila de 'content' para extraer y alinear los datos con las columnas esperadas.\n",
        "    \"\"\"\n",
        "    content = row['content']\n",
        "    timestamp = row['timestamp']\n",
        "\n",
        "    # Extraer todos los valores entre comillas dobles\n",
        "    valores = re.findall(r'\"(.*?)\"', content)\n",
        "\n",
        "    # Dividir los valores en bloques correspondientes a las columnas\n",
        "    registros = []\n",
        "    for i in range(0, len(valores), len(columnas_finales) - 1):  # Restamos 1 por 'Timestamp'\n",
        "        registro = valores[i:i + len(columnas_finales) - 1]\n",
        "\n",
        "        # Si faltan valores, completar con None (NaN)\n",
        "        while len(registro) < len(columnas_finales) - 1:\n",
        "            registro.append(None)\n",
        "\n",
        "        # Agregar el timestamp al final del registro\n",
        "        registro.append(timestamp)\n",
        "\n",
        "        registros.append(registro)\n",
        "\n",
        "    # Convertir los registros en un DataFrame\n",
        "    temp_df = pd.DataFrame(registros, columns=columnas_finales)\n",
        "    return temp_df\n",
        "\n",
        "# Procesar todas las filas de la tabla\n",
        "dfs_procesados = []\n",
        "\n",
        "for _, row in data.iterrows():\n",
        "    df_temp = procesar_content(row)\n",
        "    dfs_procesados.append(df_temp)\n",
        "\n",
        "# Concatenar los resultados\n",
        "resultado_df = pd.concat(dfs_procesados, ignore_index=True)\n",
        "\n",
        "# Mostrar el resultado\n",
        "print(\"Resultado final alineado:\")\n",
        "print(resultado_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQvvpdTWAxC-",
        "outputId": "be85f6e2-14ea-4b6c-d4da-1019ac730a4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultado final alineado:\n",
            "   Ticker           Sector            Nombre      Var     %Var  Ratio vol  \\\n",
            "0  Ticker           Sector            Nombre      Var     %Var  Ratio vol   \n",
            "1    XPON      Industrials    EXPION360 INC.    -0,11   -5,47%   12,74489   \n",
            "2    AMLI  Basic Materials  AMERICAN LITHIUM  -0,1888  -30,20%  12,268837   \n",
            "3      TC      Industrials      TUANCHE LTD.  -0,0789   -8,58%  11,830085   \n",
            "4    NXGL      Health Care        NEXGEL INC    +0,65  +18,47%  11,595072   \n",
            "\n",
            "   Último  Volumen  Capital  Spread  Inserción  Anterior  Vol V  Vol C  \\\n",
            "0  Último  Volumen  Capital  Spread  Inserción  Anterior  Vol V  Vol C   \n",
            "1    1,90  845.041   1.606k    0,04   22:28:27      2,01    300    100   \n",
            "2  0,4364   6.343k   2.768k  0,0064   22:28:27    0,6252    100  2.000   \n",
            "3  0,8411  632.577  532.060  0,0111   22:28:27    0,9200    100    200   \n",
            "4    4,17  496.012   2.068k    0,17   22:28:27      3,52    500    900   \n",
            "\n",
            "   Mínimo  Máximo  Compra  Apertura   Venta            Timestamp  \n",
            "0  Mínimo  Máximo  Compra  Apertura   Venta  2024-12-11 21:33:54  \n",
            "1    1,83    2,75    1,94      2,01    1,90  2024-12-11 21:33:54  \n",
            "2  0,4007  0,5590  0,4364    0,5488  0,4300  2024-12-11 21:33:54  \n",
            "3  0,8000    1,38  0,8411    0,9800  0,8300  2024-12-11 21:33:54  \n",
            "4    3,45    4,20    4,17      3,50    4,00  2024-12-11 21:33:54  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminar filas donde 'Ticker' sea igual a 'Ticker' (nombres de columna repetidos)\n",
        "resultado_df = resultado_df[resultado_df['Ticker'] != 'Ticker']"
      ],
      "metadata": {
        "id": "ghKh-IfFA-fi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Nos aseguramos que cada celda del CSV se encuentre sobre el margen derecho, por cuestiones de estetica:\n",
        "pd.set_option('display.max_colwidth', None)"
      ],
      "metadata": {
        "id": "HSczTwc4DDEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos una primer columna de ID autonumerico para cada ticker\n",
        "resultado_df['ID'] = range(1, len(resultado_df) + 1)"
      ],
      "metadata": {
        "id": "uiqHyDAFO0Te"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exportar a CSV\n",
        "output_path = '/content/drive/MyDrive/Proyecto_SmallCaps/BBDD/All_data_reorganizado/all_data_reorganizado.csv'\n",
        "resultado_df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"Archivo CSV exportado correctamente a: {output_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgvQ-UQfA4Fx",
        "outputId": "13c6dd8d-505b-4892-a74f-1e255c79f160"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo CSV exportado correctamente a: /content/drive/MyDrive/Proyecto_SmallCaps/BBDD/All_data_reorganizado/all_data_reorganizado.csv\n"
          ]
        }
      ]
    }
  ]
}